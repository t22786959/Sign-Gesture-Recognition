{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOyFBgYscPHiMiOUszrpp1w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!git clone https://github.com/t22786959/Sign-Gesture-Recognition.git\n","%cd Sign-Gesture-Recognition/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOBArgc2BlFA","executionInfo":{"status":"ok","timestamp":1686060917386,"user_tz":-480,"elapsed":607,"user":{"displayName":"朱庭佑","userId":"08758356564314221944"}},"outputId":"f61bbdab-aa5b-42f9-faba-decf32abdd54"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Sign-Gesture-Recognition'...\n","remote: Enumerating objects: 11, done.\u001b[K\n","remote: Counting objects: 100% (11/11), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 11 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (11/11), 4.10 MiB | 10.54 MiB/s, done.\n","/content/Sign-Gesture-Recognition/Sign-Gesture-Recognition\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"id":"YVj86sXwXS1C","executionInfo":{"status":"ok","timestamp":1686060917387,"user_tz":-480,"elapsed":4,"user":{"displayName":"朱庭佑","userId":"08758356564314221944"}}},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","\n","from sklearn.model_selection import train_test_split\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.metrics import accuracy_score\n","from keras.models import load_model\n","\n","from google.colab.patches import cv2_imshow\n","import cv2\n","from PIL import Image\n","import tkinter as tk"]},{"cell_type":"code","source":["!apt-get install swig cmake libopenmpi-dev zlib1g-dev xvfb x11-utils ghostscript ffmpeg -qq #remove -qq for full output\n","!pip install pyvirtualdisplay ghostscript"],"metadata":{"id":"PbpiJ1EAXTd0","executionInfo":{"status":"ok","timestamp":1686060934966,"user_tz":-480,"elapsed":17583,"user":{"displayName":"朱庭佑","userId":"08758356564314221944"}},"outputId":"e493924d-53c7-41d2-ac67-e25c37f5b83d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n","Requirement already satisfied: ghostscript in /usr/local/lib/python3.10/dist-packages (0.7)\n","Requirement already satisfied: setuptools>=38.6.0 in /usr/local/lib/python3.10/dist-packages (from ghostscript) (67.7.2)\n"]}]},{"cell_type":"markdown","source":["CUSTOM DATA INFERENCE"],"metadata":{"id":"RtfeZEHinzMh"}},{"cell_type":"code","source":["char = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n","path = 'data/'\n","allFileList = os.listdir(path)\n","# allFileList.remove('.ipynb_checkpoints')\n","allFileList.sort()\n","\n","ret = []\n","for file in allFileList:\n","  img_dir = os.path.join(path,file)\n","  img = cv2.imread(img_dir,0)\n","  \n","  img = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)\n","  img = cv2.flip(img, 1)\n","\n","  img = np.reshape(img, (1, 28, 28, 1))\n","\n","  model = load_model('model.h5')\n","  y_pred = model.predict(img)\n","  y_pred = y_pred.tolist()\n","  print(y_pred)\n","  ret.append(char[y_pred[0].index(1)])\n","\n","print(ret)"],"metadata":{"id":"u4jIDvjOHjgV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686060936782,"user_tz":-480,"elapsed":1820,"user":{"displayName":"朱庭佑","userId":"08758356564314221944"}},"outputId":"7bf08dc1-34ad-4d39-e835-ff1425e81561"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 239ms/step\n","[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdcbbfac280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 133ms/step\n","[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdcbbface50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 123ms/step\n","[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n","['A', 'B', 'C']\n"]}]},{"cell_type":"markdown","source":["Camera Real Time Inference"],"metadata":{"id":"NoTiz4ajLSym"}},{"cell_type":"code","source":["# import dependencies\n","!pip install mediapipe\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n","import tensorflow as tf\n","import cv2\n","import mediapipe as mp\n","from keras.models import load_model\n","import numpy as np\n","import time\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time"],"metadata":{"id":"rBccTKOZED9R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686060945042,"user_tz":-480,"elapsed":8266,"user":{"displayName":"朱庭佑","userId":"08758356564314221944"}},"outputId":"4022e5d1-9273-4d77-8f8b-b33b376d5322"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.1)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.1.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.3.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.22.4)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.7.0.72)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n","Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.6)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"]}]},{"cell_type":"code","source":["# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes"],"metadata":{"id":"vadj7f4qED_7","executionInfo":{"status":"ok","timestamp":1686060945043,"user_tz":-480,"elapsed":11,"user":{"displayName":"朱庭佑","userId":"08758356564314221944"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","  \n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data"],"metadata":{"id":"s7zVSnuDEEB8","executionInfo":{"status":"ok","timestamp":1686060945044,"user_tz":-480,"elapsed":10,"user":{"displayName":"朱庭佑","userId":"08758356564314221944"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["mphands = mp.solutions.hands\n","hands = mphands.Hands()\n","mp_drawing = mp.solutions.drawing_utils"],"metadata":{"id":"O4XVmzXRGnhO","executionInfo":{"status":"ok","timestamp":1686060945044,"user_tz":-480,"elapsed":10,"user":{"displayName":"朱庭佑","userId":"08758356564314221944"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","# initialze bounding box to empty\n","bbox = ''\n","count = 0 \n","while True:\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","\n","    # convert JS response to OpenCV Image\n","    frame = js_to_image(js_reply[\"img\"])\n","    h, w, c = frame.shape\n","\n","    # create transparent overlay for bounding box\n","    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n","\n","    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    result = hands.process(framergb)\n","    \n","    hand_landmarks = result.multi_hand_landmarks\n","\n","\n","    if hand_landmarks:\n","      \n","      for handLMs in hand_landmarks:\n","        \n","        x_max = 0\n","        y_max = 0\n","        x_min = w\n","        y_min = h\n","        for lm in handLMs.landmark:\n","          x, y = int(lm.x * w), int(lm.y * h)\n","          if x > x_max:\n","              x_max = x\n","          if x < x_min:\n","              x_min = x\n","          if y > y_max:\n","              y_max = y\n","          if y < y_min:\n","              y_min = y\n","        y_min -= 20\n","        y_max += 20\n","        x_min -= 20\n","        x_max += 20\n","        cv2.rectangle(bbox_array, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n","        mp_drawing.draw_landmarks(frame, handLMs, mphands.HAND_CONNECTIONS)\n","    \n","      framergb = framergb[y_min:y_max, x_min:x_max]\n","      print(framergb.shape)\n","      framergb = cv2.resize(framergb,(28,28))\n","      \n","      char = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n","      framergb = cv2.cvtColor(framergb, cv2.COLOR_RGB2GRAY)\n","      framergb = np.reshape(framergb, (1, 28, 28, 1))\n","      model = load_model('model.h5')\n","      y_pred = model.predict(framergb)\n","      y_pred = y_pred.tolist()\n","      \n","      print('\\rpredicted:', char[y_pred[0].index(1)], end=\"\")\n","\n","    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n","    # convert overlay of bbox into bytes\n","    bbox_bytes = bbox_to_bytes(bbox_array)\n","    # update bbox so next frame gets new overlay\n","    bbox = bbox_bytes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":44},"id":"TaBGL8yjEALo","outputId":"85c469c0-12e7-4de0-b54d-95ad5f13efa3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    "]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"kvfzno8pEAOL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FWijDT7aEAQd"},"execution_count":null,"outputs":[]}]}